{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DLGC - GPU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPKQqK9fP8NAmNAIk4Z9Bji",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thq4n/Learn-Colab/blob/main/DLGC_GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiU9vkxWpGsn",
        "outputId": "eb1ee92d-414d-419f-b759-a2ea3c3c50df"
      },
      "source": [
        "import torch\n",
        "torch.cuda.is_available()\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtlIKjIu3i7W",
        "outputId": "462e0ae0-0efc-4a7e-81a8-e437842bde08"
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp37-none-any.whl size=7411 sha256=a9de78d37a3eb4f76e1f89125c33d22cd73bdf5a761ad68ddb040033ad610b1b\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.7 GB  | Proc size: 270.3 MB\n",
            "GPU RAM Free: 15106MB | Used: 3MB | Util   0% | Total 15109MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd3qYq-u9-hi"
      },
      "source": [
        "device = torch.device('cuda')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPm1L4qu_bTO",
        "outputId": "f5039e7e-4ecf-4b93-a7dd-23f3180df9d5"
      },
      "source": [
        "a = torch.rand(3,3)\n",
        "a"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1755, 0.3960, 0.8945],\n",
              "        [0.0653, 0.2701, 0.7464],\n",
              "        [0.5993, 0.0473, 0.1183]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOOj9Fy0_g5k",
        "outputId": "2d9bf4b8-c176-411f-a323-2df9965ad568"
      },
      "source": [
        "b = torch.rand(3,3).to(device)\n",
        "b"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0971, 0.7842, 0.3880],\n",
              "        [0.0561, 0.2479, 0.8029],\n",
              "        [0.0998, 0.0979, 0.1528]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LoJyY7P_p1l",
        "outputId": "77939e36-d714-40b0-dfcf-215318b8ead3"
      },
      "source": [
        "c = torch.rand(3,3).cuda()\n",
        "c"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5428, 0.8196, 0.9012],\n",
              "        [0.3033, 0.3713, 0.1549],\n",
              "        [0.8149, 0.0441, 0.3320]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23kHLOGb_-SP"
      },
      "source": [
        "import time "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3qB6Pvi__WQ",
        "outputId": "c25ba38f-5548-47f9-8b3c-f7c9beaecf2e"
      },
      "source": [
        "a = torch.ones(3000,3000)\n",
        "b = torch.ones(3000,3000).cuda()\n",
        "start = time.time()\n",
        "for _ in range(10000):\n",
        "    a+=a\n",
        "duration = time.time() - start\n",
        "print (duration)\n",
        "\n",
        "start = time.time()\n",
        "for _ in range(10000):\n",
        "    b+=b\n",
        "duration = time.time() - start\n",
        "print (duration)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25.03040337562561\n",
            "2.725353956222534\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}